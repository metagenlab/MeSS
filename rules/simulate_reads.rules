checkpoint generate_table_summary:
    conda: '../envs/simulate_reads.yml'

    input: 'table_combined.tsv'

    output: 'metagenome_summary.tsv'

    params: proportion_reads = config['proportion_reads']

    threads: 1

    script: 'calculate_reads.py'



rule decompress_assemblies:
    conda: '../envs/simulate_reads.yml'

    input: 'assembly_gz/{sample}.fna.gz'

    output: temp('assembly_fna/{sample}.fna')

    shell: 'zcat {input[0]} > {output[0]}'


rule concat_scaffolds:
    input: 'assembly_fna/{sample}.fna'

    output: temp('concat/{sample}.fna')

    shell: "sed '1!{{/^>/d;}}' {input[0]} > {output[0]}"

import pandas as pd
def calculate_reads(wildcards):
    total=config['total_amount_reads']
    checkpoint_output = checkpoints.generate_table_summary.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t',index_col=0)
    prop=table.loc[wildcards.sample]['PercentReads']
    read_nb=int(prop*total)
    print('Simulating {0} reads'.format(read_nb))
    return read_nb

rule generate_reads_single:
    conda: '../envs/simulate_reads.yml'

    input: 'concat/{sample}.fna'

    output: temp('simulated_single_reads/{sample,[A-Za-z0-9_\.]+}_R{dir}.fq')

    params: seq_system=config['illumina_sequencing_system'],
            read_length=config['read_length'],
            read_num=calculate_reads

    shell: 'art_illumina -ss {params.seq_system} -na -i {input} \
    -l {params.read_length} -c {params.read_num} -o simulated_single_reads/{wildcards.sample}_R'


rule generate_reads_paired:
    conda: '../envs/simulate_reads.yml'

    input: 'concat/{sample}.fna'

    output: temp('simulated_paired_reads/{sample,[A-Za-z0-9_\.]+}_R1.fq'),
            temp('simulated_paired_reads/{sample,[A-Za-z0-9_\.]+}_R2.fq')

    params: seq_system=config['illumina_sequencing_system'],
            read_length=config['read_length'],
            read_num=calculate_reads,
            mean_frag_len=config['mean_fragment_length'],
            sd=config['sd_fragment_length']

    shell: 'art_illumina -ss {params.seq_system} -na -i {input} -p -m {params.mean_frag_len} -s {params.sd} \
    -l {params.read_length} -c {params.read_num} -o simulated_paired_reads/{wildcards.sample}_R'

def list_samples(wildcards):
    checkpoint_output = checkpoints.generate_table_summary.get(**wildcards).output[0]
    table=pd.read_csv(checkpoint_output,delimiter='\t')
    acc=list(table['AssemblyNames'])
    expd=expand('simulated_{{format}}_reads/{sample}_R{{dir}}.fq',sample=acc)
    return expd


rule combine_fastq:
    input: list_samples

    output: temp('combined_{format}_shuffled/combined_reads_R{dir}.fq')

    shell:
        '''
        cat {input} >> {output}
        '''

rule shuffle_fastq:
    input: 'combined_{format}_shuffled/combined_reads_R{dir}.fq'

    output: 'combined_{format}_shuffled/shuffled_samples_R{dir}.fq'

    params: seed=config['shuffling_seed'],pipe_path=config['pipeline_path']

    shell:"{params.pipe_path}/rules/shuffle.sh {input} {output} {params.seed}"

#rule compress_fastq:
 #   input: '{anyfq}.fq'

  #  output: '{anyfq}.fq.gz'

   # shell: "gzip {input} > {output}"


