import pandas as pd
import os
import random
def list_downloaded_assemblies(wildcards):
    checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
    tb=pd.read_csv(checkpoint_output,sep='\t')
    filenames=tb['AssemblyNames']
    expd=expand('assembly_gz/{assemblyname}.fna.gz',assemblyname=filenames)
    return expd

def get_input_value(path):
    tb=pd.read_csv(path,sep='\t')
    acceptedvals=['Coverage','PercentReads','RelativeProp']
    lastcol=tb.columns[len(tb.columns)-1]
    nans=tb[lastcol].isna().sum()
    if nans>0:
        print(f'{nans} values in {lastcol} are not set, make sure to input values')
    if lastcol in acceptedvals:
        print(f'taking {lastcol} as input to simulate reads')
    else:
        print(f'{lastcol} is not recognized as an input to simulate reads')
    return lastcol

input_val=get_input_value(config['input_table_path'])


rule populate_table:#merge assembly table with user input values
    input: assemblies=list_downloaded_assemblies,
           input_tb=config['input_table_path'],
           assemblies_tb='assemblies-summary.tsv'

    output: temp('merged.tsv')

    params: proportion_reads = config['proportion_reads'],
            val=input_val

    script: 'populate_table.py'


rule decompress_assemblies:
    input: 'assembly_gz/{assemblyname}.fna.gz'

    output: temp('simreads/{community}-{assemblyname}.fna')

    shell: 'zcat {input[0]} > {output[0]}'


rule merge_contigs:
    conda: "../envs/biopython.yml"

    input: 'simreads/{community}-{assemblyname}.fna'

    output: temp('simreads/{community}-{assemblyname}.fa') #.fa because ouptput files must have unique names (otherwise we have to create a new dir, or use shadow rules)

    script: "merge_contigs.py"



checkpoint create_read_counts_table:
    '''
    Rule for generating a table per sample with read counts for each genome 
    '''
    input: 'merged.tsv'

    output: krona_output=temp('krona/{community}-simrep-{rep}.txt'),
            rc_table='summary-{community}-{rep}.tsv'

    params: value=input_val

    log: "logs/read_counts_table/{community}-{rep}.txt"

    script: 'read_counts_table.py'



rule create_krona_chart:
    conda: "../envs/krona.yml"

    input: 'krona/{community}-simrep-{rep}.txt'

    output: 'krona/{community}-simrep-{rep}.html'

    log: 'logs/krona/{community}-simrep-{rep}.log'

    shell: 'ktImportText -o {output} {input} &> {log}'



def get_read_num(wildcards):
    rule_output = checkpoints.create_read_counts_table.get(**wildcards).output["rc_table"]
    table = pd.read_csv(rule_output,delimiter='\t',index_col='AssemblyNames')
    nb_reads=table.loc[wildcards.assemblyname]['SimReads']
    return nb_reads


if config['read_status']=='paired' and config['seq_tech']=='illumina':
    rule generate_illumina_paired_reads:
        conda: "../envs/art.yml"

        input: fa='simreads/{community}-{assemblyname}.fa',
                tab='summary-{community}-{rep}.tsv'

        output: temp('simreads/{community}-paired-simrep-{rep,[0-9]+}-{assemblyname}_R1.fq'),
                temp('simreads/{community}-paired-simrep-{rep,[0-9]+}-{assemblyname}_R2.fq')

        params: seq_system=config['illumina_sequencing_system'],
                read_length=config['illumina_read_len'],
                mean_frag_len=config['illumina_mean_frag_len'],
                sd=config['illumina_sd_frag_len'],
                read_num=lambda wildcards:get_read_num(wildcards),
                random_seed=lambda wildcards: seed_dic[int(wildcards.rep)]

        resources: nb_simulation=1

        log: "logs/art_illumina/{community}-replicate-{rep}-{assemblyname}.log"

        shell: 'art_illumina -rs {params.random_seed} -ss {params.seq_system} -na -i {input.fa} -p -m {params.mean_frag_len} -s {params.sd} \
        -l {params.read_length} -c {params.read_num} -o simreads/{wildcards.community}/paired-simrep-{wildcards.rep}-{wildcards.assemblyname}_R &> {log}'

    # rule count_simulated_reads_from_paired_fq:
    #     input: r1='simreads/{community}/paired-simrep{rep,[0-9]+}-{assemblyname}_R1.fq',
    #            r2='simreads/{community}/paired-simrep{rep,[0-9]+}-{assemblyname}_R2.fq'
    #
    #     output: r1='simreads/{community}/paired-simrep{rep,[0-9]+}-{assemblyname}_R1.txt',
    #             r2='simreads/{community}/paired-simrep{rep,[0-9]+}-{assemblyname}_R2.txt'
    #
    #     shell:
    #         '''
    #         awk "{{s++}END{{print s/4}}" {input.r1} > {output.r1}
    #         awk "{{s++}END{{print s/4}}" {input.r2} > {output.r2}
    #         '''

if config['read_status']=='single' and config['seq_tech']=='illumina':
    rule generate_illumina_single_reads:
        container: "../envs/art.yml"

        input: fa='simreads/{community}-{assemblyname}.fa',
                tab='summary-{community}-{rep}.tsv'

        output: temp('simreads/{community}-single-simrep-{rep}-{assemblyname}_R1.fq')

        params: seq_system=config['illumina_sequencing_system'],
                read_length=config['illumina_read_len'],
                read_num=lambda wildcards:get_read_num(wildcards),
                random_seed=lambda wildcards: seed_dic[int(wildcards.rep)]

        resources: nb_simulation=1

        log: "logs/art_illumina/{community}-replicate-{rep}-{assemblyname}.log"

        shell: 'art_illumina -rs {params.random_seed} -ss {params.seq_system} -na -i {input.fa} \
        -l {params.read_length} -c {params.read_num} -o simreads/{wildcards.community}/single-simrep-{wildcards.rep}-{wildcards.assemblyname}_R1 &> {log}'

    # rule count_simulated_reads_from_single_fq:
    #     input: 'simreads/{community}/single-simrep{rep}-{assemblyname}_R1.fq'
    #
    #     output: 'simreads/{community}/single-simrep{rep}-{assemblyname}_R1.txt'
    #
    #     shell:
    #         '''
    #         awk "{{s++}END{{print s/4}}" {input} > {output}
    #         '''

def get_coverage(wildcards):
    rule_output = checkpoints.create_read_counts_table.get(**wildcards).output["rc_table"]
    tb=pd.read_csv(rule_output,delimiter='\t',index_col='AssemblyNames')
    cov=tb.loc[wildcards.assemblyname]['Coverage']
    return cov


if config['read_status']=='single' and config["seq_tech"]=='longreads':
    rule generate_long_reads:
        singularity: 'docker://metagenlab/pbsim2:latest'

        input: fa='simreads/{community}-{assemblyname}.fa',
                tab='summary-{community}-{rep}.tsv'
        output: temp('simreads/{community}-simrep-{rep}-{assemblyname}_0001.fastq'),
                temp('simreads/{community}-simrep-{rep}-{assemblyname}_0001.maf'),
                temp('simreads/{community}-simrep-{rep}-{assemblyname}_0001.ref'),

        params: chemistry=config["chemistry"],
                min_read_len=config["longreads_min_len"],
                max_read_len=config["longreads_max_len"],
                sd_read_len=config["longreads_sd_len"],
                mean_read_len=config["longreads_mean_len"],
                accuracy=config["longreads_mean_acc"],
                diff_ratio=config["difference_ratio"],
                coverage=lambda wildcards:get_coverage(wildcards),
                seed=lambda wildcards: seed_dic[int(wildcards.rep)]

        resources: nb_simulation=1

        log: "logs/pbsim2/{community}-replicate-{rep}-{assemblyname}.log"

        shell: "pbsim --prefix simreads/{wildcards.community}-simrep-{wildcards.rep}-{wildcards.assemblyname} --id-prefix {wildcards.assemblyname} \
        --depth {params.coverage} --length-min {params.min_read_len} --length-max {params.max_read_len} \
        --difference-ratio {params.diff_ratio} --seed {params.seed} --hmm_model /pbsim2/data/{params.chemistry}.model \
        --length-mean {params.mean_read_len} --length-sd {params.sd_read_len} {input.fa} &> {log}"




def combine_fastq_input(wildcards):
    table = checkpoints.create_read_counts_table.get(**wildcards).output["rc_table"]
    tb=pd.read_csv(table,delimiter='\t')
    filenames=tb['AssemblyNames']
    if config['seq_tech']=='illumina' and config['read_status']=='paired':
        return expand(f'simreads/{wildcards.community}-paired-simrep-{wildcards.rep}-{{assemblyname}}_R{wildcards.rd}.fq',assemblyname=filenames)
    if config['seq_tech']=='illumina' and config['read_status']=='single':
        return expand(f'simreads/{wildcards.community}-single-simrep-{wildcards.rep}-{{assemblyname}}_R1.fq',
                assemblyname=filenames)
    if config['seq_tech'] == 'longreads':
        return expand(f'simreads/{wildcards.community}-simrep-{wildcards.rep}-{{assemblyname}}_0001.fastq',assemblyname=filenames)


rule combine_fastq:
    input: combine_fastq_input

    output: temp('simreads/{community}-{rep}-combined_R{rd}.fq')

    resources: parallel_cat=1

    shell:
        '''
        cat {input} >> {output}
        '''

# def combine_fastq_text_input(wildcards):
#     checkpoint_output = checkpoints.combine_assembly_tables.get(**wildcards).output[0]
#     tb=pd.read_csv(checkpoint_output,delimiter='\t')
#     filenames=tb['AssemblyNames']
#     if config['read_status']=='paired':
#         return expand(f'simreads/{wildcards.community}/paired-simrep{wildcards.rep}-{{assemblyname}}_R{wildcards.rd}.txt',assemblyname=filenames)
#     else:
#         return expand(f'simreads/{wildcards.community}/single-simrep{wildcards.rep}-{{assemblyname}}_R1.txt',assemblyname=filenames)

pipeline_path=workflow.basedir
random.seed(config["set_seed"])
nb_rep=config["replicates"]
rep_list=list(range(1,nb_rep+1))
seed_list=random.sample(range(1,1000000),len(rep_list))
seed_dic=dict(zip(rep_list,seed_list))

rule shuffle_fastq:
    input: 'simreads/{community}-{rep}-combined_R{rd}.fq'

    output: 'simreads/{community}-{rep}_R{rd}.fastq'

    params: seed=lambda wildcards: seed_dic[int(wildcards.rep)],
            script_path=os.path.join(pipeline_path,'shuffle.sh')

    log: "logs/shuffling/{community}-{rep}-{rd}-shuffling-seed.log"

    shell:
        """
        {params.script_path} {input} {output} {params.seed} &> {log}
        """


rule compress_fastq:
    conda: "../envs/pigz.yml"

    input: 'simreads/{community}-{rep}_R{rd}.fastq'

    output: 'simreads/{community}-{rep}_R{rd}.fastq.gz'

    threads: 12

    shell:
        """
        pigz -p {threads} {input}
        """


