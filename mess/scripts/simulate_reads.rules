import pandas as pd
import os
import random
community_name=config["community_name"]
pipeline_path=workflow.basedir
random.seed(config["set_seed"])
nb_rep=config["replicates"]
rep_list=list(range(1,nb_rep+1))
seed_list=random.sample(range(1,1000000),len(rep_list))
seed_dic=dict(zip(rep_list,seed_list))

def get_input_value(path):
    """
    Function that parses input table and raises exceptions if there are NA in the table
    """
    tb=pd.read_csv(path,sep='\t')
    acceptedvals=['Reads','Coverage','PercentReads','RelativeProp']
    lastcol=tb.columns[len(tb.columns)-1]
    nans=tb[lastcol].isna().sum()
    if nans>0:
        raise Exception(f'{nans} values in {lastcol} are not set, make sure to input values')
    if lastcol in acceptedvals:
        return lastcol
    else:
        raise Exception(f'{lastcol} is not recognized as an input to simulate reads')

input_val=get_input_value(config['input_table_path'])


rule create_read_counts_table:
    '''
    Rule for generating a table per sample with read counts for each genome 
    '''
    input: input_tb = config['input_table_path'],
           assemblies_tb = f'{community_name}-assemblies-summary.tsv'

    output: rc_table='summary-{community}-{rep}.tsv',
            krona_output=temp('krona/{community}-simrep-{rep}.txt')

    params: value=input_val

    log: "logs/read_counts_table/{community}-{rep}.txt"

    script: 'read_counts_table.py'


rule create_krona_chart:
    conda: "../envs/krona.yml"

    input: 'krona/{community}-simrep-{rep}.txt'

    output: 'krona/{community}-simrep-{rep}.html'

    log: 'logs/krona/{community}-simrep-{rep}.log'

    shell: 'ktImportText -o {output} {input} &> {log}'


rule decompress_assemblies:
    input: f'assembly_gz/{community_name}/{{assemblyname}}_genomic.fna.gz',
            f"assembly_gz/{community_name}/{community_name}.done"

    output: temp(f'assembly_gz/{community_name}/{{assemblyname,[0-9a-zA-Z._-]+}}.fna')

    benchmark: "benchmark/decompress/{assemblyname}.txt"

    shell: 'zcat {input[0]} > {output}'


rule merge_contigs:
    conda: "../envs/biopython.yml"

    input: f'assembly_gz/{community_name}/{{assemblyname}}.fna'

    output: temp('simreads/{community,[-_0-9a-zA-Z]+}-{assemblyname,[0-9a-zA-Z._-]+}.fa')

    benchmark: "benchmark/merge/{community}-{assemblyname}.txt"

    script: "merge_contigs.py"


if config['seq_tech']=='illumina':
    def get_read_num(wildcards,table):
        if not os.path.exists(table):
            return -1
        with open(table) as f:
            tb = pd.read_csv(f,delimiter='\t',index_col='AssemblyNames')
            reads = tb.loc[wildcards.assemblyname]['Reads']
            return reads

    if config['read_status']=='paired':
        rule generate_illumina_paired_reads:
            conda: "../envs/art.yml"

            input:  fa='simreads/{community}-{assemblyname}.fa',
                    tab='summary-{community}-{rep}.tsv'

            output: temp('simreads/{community,[-_0-9a-zA-Z]+}-paired-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_R1.fq'),
                    temp('simreads/{community,[-_0-9a-zA-Z]+}-paired-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_R2.fq')

            params: seq_system = config['illumina_sequencing_system'],
                    read_length = config['illumina_read_len'],
                    mean_frag_len = config['illumina_mean_frag_len'],
                    sd = config['illumina_sd_frag_len'],
                    read_num = lambda wildcards, input: get_read_num(wildcards, input.tab),
                    random_seed = lambda wildcards: seed_dic[int(wildcards.rep)]

            resources: nb_simulation=1

            log: "logs/art_illumina/{community}-replicate-{rep}-{assemblyname}.log"

            benchmark: "benchmark/art_illumina/{community}-{rep}-{assemblyname}.txt"

            shell:
                """
                art_illumina -d {wildcards.assemblyname} -rs {params.random_seed} -ss {params.seq_system} -na -i {input.fa} -p \
                -nf 1 -m {params.mean_frag_len} -s {params.sd} -l {params.read_length} -c {params.read_num} \
                -o simreads/{wildcards.community}-paired-simrep-{wildcards.rep}-{wildcards.assemblyname}_R &> {log}
                """

    if config['read_status']=='single':
        rule generate_illumina_single_reads:
            conda: "../envs/art.yml"

            input: fa='simreads/{community}-{assemblyname,[.0-9a-zA-Z_-]}.fa',
                    tab='summary-{community}-{rep}.tsv'

            output: temp('simreads/{community,[-_0-9a-zA-Z]+}-single-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_R1.fq')

            params: seq_system = config['illumina_sequencing_system'],
                    read_length = config['illumina_read_len'],
                    read_num = lambda wildcards, input: get_read_num(wildcards, input.tab),
                    random_seed = lambda wildcards: seed_dic[int(wildcards.rep)]

            resources: nb_simulation=1

            log: "logs/art_illumina/{community}-replicate-{rep}-{assemblyname}.log"

            benchmark: "benchmark/art_illumina/{community}-{rep}-{assemblyname}.txt"

            shell:
                """
                art_illumina -d {wildcards.assemblyname} -rs {params.random_seed} -ss {params.seq_system} -na -i {input.fa} \
                -nf 1 -l {params.read_length} -c {params.read_num} \
                -o simreads/{wildcards.community}-single-simrep-{wildcards.rep}-{wildcards.assemblyname}_R1 &> {log}
                """

if config['seq_tech']=='longreads':
    def get_coverage(wildcards, table):
        if not os.path.exists(table):
            return -1
        with open(table) as f:
            tb = pd.read_csv(f,delimiter='\t',index_col='AssemblyNames')
            cov = tb.loc[wildcards.assemblyname]['Coverage']
            return cov

    rule generate_long_reads:
        conda: '../envs/pbsim2.yml'

        input: fa='simreads/{community}-{assemblyname}.fa',
               tab='summary-{community}-{rep}.tsv'
        output: temp('simreads/{community,[-_0-9a-zA-Z]+}-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_0001.fastq'),
                temp('simreads/{community,[-_0-9a-zA-Z]+}-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_0001.maf'),
                temp('simreads/{community,[-_0-9a-zA-Z]+}-simrep-{rep,[0-9]+}-{assemblyname,[0-9a-zA-Z._-]+}_0001.ref'),

        params: chemistry = config["chemistry"],
                min_read_len = config["longreads_min_len"],
                max_read_len = config["longreads_max_len"],
                sd_read_len = config["longreads_sd_len"],
                mean_read_len = config["longreads_mean_len"],
                accuracy = config["longreads_mean_acc"],
                diff_ratio = config["difference_ratio"],
                coverage = lambda wildcards, input: get_coverage(wildcards, input.tab),
                seed = lambda wildcards: seed_dic[int(wildcards.rep)]

        resources: nb_simulation=1

        log: "logs/pbsim2/{community}-replicate-{rep}-{assemblyname}.log"

        benchmark: "benchmark/pbsim2/{community}-{rep}-{assemblyname}.txt"

        shell:
            """
            pbsim --prefix simreads/{wildcards.community}-simrep-{wildcards.rep}-{wildcards.assemblyname} \
            --id-prefix {wildcards.assemblyname} --depth {params.coverage} --length-min {params.min_read_len} \
            --length-max {params.max_read_len} --difference-ratio {params.diff_ratio} --seed {params.seed} \
            --hmm_model ${{CONDA_PREFIX}}/data/{params.chemistry}.model --length-mean {params.mean_read_len} \
            --length-sd {params.sd_read_len} {input.fa} &> {log}
            """

def combine_fastq_input(wildcards):
    checkpoint_output = checkpoints.download_assemblies.get(**wildcards).output[0]
    directory = '/'.join((checkpoint_output.split('/')[0:2]))
    assemblynames = glob_wildcards(os.path.join(directory, '{i}_genomic.fna.gz')).i
    if config['seq_tech']=='illumina' and config['read_status']=='paired':
        return expand('simreads/{community}-paired-simrep-{rep}-{assemblyname}_R{{rd}}.fq',
            community=community_name,rep=rep_list,assemblyname=assemblynames)
    if config['seq_tech']=='illumina' and config['read_status']=='single':
        return expand('simreads/{community}-single-simrep-{rep}-{assemblyname}_R1.fq',
            community=community_name,rep=rep_list,assemblyname=assemblynames)
    if config['seq_tech'] == 'longreads':
        return expand('simreads/{community}-simrep-{rep}-{assemblyname}_0001.fastq',
            community=community_name,rep=rep_list,assemblyname=assemblynames)


rule concat_fastqs:
    input: combine_fastq_input

    output: temp('simreads/{community}-{rep}_R{rd}.unshuffled.fq')

    resources: parallel_cat = 1

    benchmark: "benchmark/concat/{community}-{rep}_{rd}.txt"

    shell:
        """
        cat {input} > {output}
        """


rule shuffle_fastqs:
    conda: "../envs/seqkit.yml"

    input: 'simreads/{community}-{rep}_R{rd}.unshuffled.fq'

    output: 'simreads/{community}-{rep}_R{rd}.fq.gz'

    params: seed = lambda wildcards: seed_dic[int(wildcards.rep)]

    log: "logs/shuffling/{community}-{rep}-{rd}.log"

    benchmark: "benchmark/shuffle/{community}-{rep}_{rd}.txt"

    threads: 15

    shell:
        """
        seqkit shuffle {input} -j {threads} -s {params.seed} -o {output}  &> {log}
        """




